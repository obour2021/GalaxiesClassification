{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import load_galaxy_data\n",
    "\n",
    "import app\n",
    "\n",
    "input_data, labels = load_galaxy_data()\n",
    "print(input_data.shape) #print shape of features\n",
    "print(labels.shape) #print shape of labels\n",
    "\n",
    "#split data into training and validation\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(input_data, labels, test_size=0.20, stratify=labels, shuffle=True, random_state=222)\n",
    "\n",
    "#data preprocessing\n",
    "data_generator = ImageDataGenerator(rescale=1./255) #Creates an ImageDataGenerator and nomalize \n",
    "\n",
    "#1) Use data_generator.flow to load the training data with batch size of 5\n",
    "training_iterator = data_generator.flow(x_train, y_train,batch_size=5)\n",
    "\n",
    "#2) Use data_generator.flow to load the validation data with batch size of 5\n",
    "validation_iterator = data_generator.flow(x_valid, y_valid, batch_size=5)\n",
    "\n",
    "#building the CNN model\n",
    "model = tf.keras.Sequential(name='Galaxies_Classification') #initilize galaxy sequential model\n",
    "\n",
    "#add an input layer\n",
    "model.add(tf.keras.Input(shape=(128,128,3)))\n",
    "\n",
    "#add Conv2D layer with 8 filters 3x3 size and stride 2\n",
    "model.add(tf.keras.layers.Conv2D(8, 3, strides=2,activation=\"relu\"))\n",
    "\n",
    "#Add first max pooling layer \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "#add another Conv2D layer with 8 filters 3x3 size and stride 2\n",
    "model.add(tf.keras.layers.Conv2D(8, 3, strides=2,activation=\"relu\"))\n",
    "\n",
    "#Add second max pooling layer \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "#add flatten layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#add hidden dense layer with 16 hidden units\n",
    "model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
    "\n",
    "#add a Dense output layer\n",
    "model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "\n",
    "#compile the model\n",
    "# Compile the model with an Adam optimizer, Categorical Cross Entropy Loss, and Accuracy and AUC metrics:\n",
    "\n",
    "model.compile(\n",
    "   optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "   loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "   metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "print(model.summary()) #print the model summary\n",
    "\n",
    "#Training the model\n",
    "#4) Use model.fit(...) to train and validate our model for 8 epochs:\n",
    "\n",
    "model.fit(\n",
    "       training_iterator,\n",
    "       steps_per_epoch=len(x_train)/5,\n",
    "       epochs=8,\n",
    "       validation_data=validation_iterator,\n",
    "       validation_steps=len(x_valid)/5)\n",
    "\n",
    "# predict and visualize\n",
    "from visualize import visualize_activations\n",
    "visualize_activations(model, validation_iterator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
